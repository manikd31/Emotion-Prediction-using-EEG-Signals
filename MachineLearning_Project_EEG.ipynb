{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import load_data\n",
    "import numpy as np\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import keras\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Dense, Activation, Dropout, SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir='./logs/{}'.format(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_from_one_hot(mat_2d):\n",
    "    mat_1d = []\n",
    "    for i in mat_2d:\n",
    "        arg = np.argmax(i) + 1\n",
    "        mat_1d.append(arg)\n",
    "        \n",
    "    return mat_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_class_imbalance(train_labels, test_labels):\n",
    "    \n",
    "    tr_lbl_dict = dict()\n",
    "    for i in range(len(train_labels)):\n",
    "        if(train_labels[i] in tr_lbl_dict):\n",
    "            tr_lbl_dict[train_labels[i]] += 1\n",
    "        else:\n",
    "            tr_lbl_dict[train_labels[i]] = 1\n",
    "\n",
    "    print(\"Train Labels Distribution\")\n",
    "    print(tr_lbl_dict)\n",
    "\n",
    "    print()\n",
    "\n",
    "    ts_lbl_dict = dict()\n",
    "    for i in range(len(test_labels)):\n",
    "        if(test_labels[i] in ts_lbl_dict):\n",
    "            ts_lbl_dict[test_labels[i]] += 1\n",
    "        else:\n",
    "            ts_lbl_dict[test_labels[i]] = 1\n",
    "\n",
    "    print(\"Test Labels Distribution\")\n",
    "    print(ts_lbl_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pca_features(trainx, testx, p=180):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    pca = PCA(n_components=p)\n",
    "\n",
    "    x_train_pca = pca.fit_transform(trainx)\n",
    "    x_test_pca = pca.transform(testx)\n",
    "    \n",
    "    stop = time.time()\n",
    "    \n",
    "    elapsed = round(stop - start, 3)\n",
    "    \n",
    "    print()\n",
    "    print(\"Time taken for PCA feature selection : {}s\".format(elapsed))\n",
    "    print()\n",
    "    \n",
    "    return x_train_pca, x_test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mms_scaled_features(trainx, testx, x_train_pca, x_test_pca):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    minmaxscaler = MinMaxScaler()\n",
    "\n",
    "    xtr_scaled_mms = minmaxscaler.fit_transform(trainx)\n",
    "    xts_scaled_mms = minmaxscaler.fit_transform(testx)\n",
    "\n",
    "    xtr_scaled_mms_pca = minmaxscaler.fit_transform(x_train_pca)\n",
    "    xts_scaled_mms_pca = minmaxscaler.fit_transform(x_test_pca)\n",
    "    \n",
    "    stop = time.time()\n",
    "    \n",
    "    elapsed = round(stop - start, 3)\n",
    "    \n",
    "    print()\n",
    "    print(\"Time taken for Min-Max feature scaling : {}s\".format(elapsed))\n",
    "    print()\n",
    "\n",
    "    return xtr_scaled_mms, xts_scaled_mms, xtr_scaled_mms_pca, xts_scaled_mms_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_std_scaled_features(trainx, testx, x_train_pca, x_test_pca):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    stdscaler = StandardScaler()\n",
    "\n",
    "    xtr_scaled_std = stdscaler.fit_transform(trainx)\n",
    "    xts_scaled_std = stdscaler.fit_transform(testx)\n",
    "\n",
    "    xtr_scaled_std_pca = stdscaler.fit_transform(x_train_pca)\n",
    "    xts_scaled_std_pca = stdscaler.fit_transform(x_test_pca)\n",
    "    \n",
    "    stop = time.time()\n",
    "    \n",
    "    elapsed = round(stop - start, 3)\n",
    "    \n",
    "    print()\n",
    "    print(\"Time taken for Standard feature scaling : {}s\".format(elapsed))\n",
    "    print()\n",
    "    \n",
    "    return xtr_scaled_std, xts_scaled_std, xtr_scaled_std_pca, xts_scaled_std_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainELM(in_data, out_data):\n",
    "        \n",
    "    elm_input = in_data\n",
    "    elm_output = out_data\n",
    "    in_shape = in_data.shape[1]\n",
    "\n",
    "    elm_hidden_nodes = 1000\n",
    "\n",
    "    A = np.random.random((in_shape, elm_hidden_nodes))\n",
    "\n",
    "    H = np.dot(elm_input, A)\n",
    "\n",
    "    # H = sigmoid(H)\n",
    "\n",
    "    Hinv = np.linalg.pinv(H)\n",
    "\n",
    "    B = np.dot(Hinv, elm_output)\n",
    "\n",
    "    pred_output = np.dot(H, B)\n",
    "\n",
    "    pred = convert_from_one_hot(pred_output)\n",
    "\n",
    "    actual = convert_from_one_hot(elm_output)\n",
    "\n",
    "    corr = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(len(actual)):\n",
    "        total += 1\n",
    "        if(pred[i] == actual[i]):\n",
    "            corr += 1\n",
    "\n",
    "    return A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testELM(in_data, out_data, A, B):\n",
    "    \n",
    "    elm_hidden_nodes = 1000\n",
    "    elm_input = in_data\n",
    "    elm_output = out_data\n",
    "    in_shape = in_data.shape[1]\n",
    "    \n",
    "    testH = np.dot(elm_input, A)\n",
    "    \n",
    "    test_pred = np.dot(testH, B)\n",
    "    \n",
    "    pred = convert_from_one_hot(test_pred)\n",
    "\n",
    "    actual = convert_from_one_hot(elm_output)\n",
    "\n",
    "    corr = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(len(actual)):\n",
    "        total += 1\n",
    "        if(pred[i] == actual[i]):\n",
    "            corr += 1\n",
    "            \n",
    "    test_acc = round(((corr/total) * 100), 2)\n",
    "\n",
    "    print(\"Classification accuracy (L = {}): {}%\".format(elm_hidden_nodes, test_acc))\n",
    "    \n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_elm_performance(xtr_scaled_std_pca, trainy, xts_scaled_std_pca, testy):\n",
    "\n",
    "    all_acc_elm = []\n",
    "    all_times_elm = []\n",
    "\n",
    "    for i in range(3):\n",
    "\n",
    "        print()\n",
    "        print()\n",
    "        print(\"Iteration {}\".format(i+1))\n",
    "        print()\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        a, beta = trainELM(xtr_scaled_std_pca, trainy)\n",
    "\n",
    "        # stop_time = time.time()\n",
    "\n",
    "        # print(\"Time elapsed (Training): {} sec\\n\".format(round(elapsed_time, 2)))\n",
    "\n",
    "        # start_time = time.time()\n",
    "\n",
    "        # #\n",
    "        # Testing Phase\n",
    "        # #\n",
    "\n",
    "        test_acc = testELM(xts_scaled_std_pca, testy, a, beta)\n",
    "\n",
    "        all_acc_elm.append(test_acc)\n",
    "\n",
    "        stop_time = time.time()\n",
    "\n",
    "        elapsed_time = round((stop_time - start_time), 3)\n",
    "        \n",
    "        all_times_elm.append(elapsed_time)\n",
    "\n",
    "        # #\n",
    "        # Training Auto-ELM\n",
    "        # #\n",
    "\n",
    "        print(\"Time elapsed (Testing): {} sec\\n\".format(elapsed_time))\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print(\"Average Testing Accuracy (ELM) : {}%\".format(np.average(all_acc_elm)))\n",
    "    \n",
    "    return all_acc_elm, all_times_elm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rf_performance(xtr_scaled_std_pca, y_train, xts_scaled_std_pca, y_test):\n",
    "    \n",
    "    all_acc_rf = []\n",
    "    all_times_rf = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        \n",
    "        print(\"Iteration {}\".format(i+1))\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        rfc = RandomForestClassifier(n_estimators=200, max_depth=5000, n_jobs=-1, verbose=0)\n",
    "\n",
    "        rfc.fit(xtr_scaled_std_pca, y_train)\n",
    "\n",
    "        tsacc = round(rfc.score(xts_scaled_std_pca, y_test) * 100, 2)\n",
    "        print(\"Testing Accuracy : %\".format(tsacc))\n",
    "        \n",
    "        stop = time.time()\n",
    "        \n",
    "        elapsed = round((stop - start), 3)\n",
    "        \n",
    "        all_times_rf.append(elapsed)\n",
    "        all_acc_rf.append(tsacc)\n",
    "    \n",
    "    print()\n",
    "    print(\"Average Testing Accuracy (RF) : {}%\".format(np.average(all_acc_rf)))\n",
    "    \n",
    "    return all_acc_rf, all_times_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch):\n",
    "    if(epoch <= 5):\n",
    "        return 1e-3\n",
    "    elif(epoch <= 10):\n",
    "        return 1e-4\n",
    "    elif(epoch <= 15):\n",
    "        return 1e-5\n",
    "    else:\n",
    "        return 1e-6\n",
    "    return 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels_for_sparse(y_train, y_test):\n",
    "\n",
    "    train_labels = y_train\n",
    "    test_labels = y_test\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_tr0 = le.fit_transform(y_train)\n",
    "    y_ts0 = le.fit_transform(y_test)\n",
    "\n",
    "    y_tr = np.reshape(y_tr0, ((len(y_tr0), 1)))\n",
    "    y_ts = np.reshape(y_ts0, ((len(y_ts0), 1)))\n",
    "    \n",
    "    return y_tr, y_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calculate_nn_performance(x_train_pca, y_tr, x_test_pca, y_ts):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(1024, name='dense_input', input_shape=(180,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # model.add(Dense(256, name='dense2'))\n",
    "    # model.add(Activation('relu'))\n",
    "    # model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(3, name='classifier'))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    print(model.summary())\n",
    "    print()\n",
    "\n",
    "    all_acc_nn = []\n",
    "    all_times_nn = []\n",
    "\n",
    "    for i in range(3):\n",
    "        \n",
    "        start = time.time()\n",
    "        print()\n",
    "        print(\"Iteration {}\".format(i+1))\n",
    "        print()\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.001), metrics=['acc'])\n",
    "        keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "        m_h = model.fit(x_train_pca, y_tr, epochs=20, batch_size=2048, validation_data=(x_test_pca, y_ts), callbacks=[tensorboard])\n",
    "        print()\n",
    "        acc = round(np.average(m_h.history['val_acc']) * 100, 2)\n",
    "        print(\"Testing Accuracy : {}%\".format(acc))\n",
    "        stop = time.time()\n",
    "        elapsed_time = round(stop-start, 3)\n",
    "        all_acc_nn.append(acc)\n",
    "        all_times_nn.append(elapsed_time)\n",
    "        print()\n",
    "        print(\"Time elapsed : {}s\".format(elapsed_time))\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print(\"Average Testing Accuracy (NN) : {}%\".format(np.average(all_acc_nn)))\n",
    "\n",
    "    return all_acc_nn, all_times_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_svm_performance(x_train_pca, y_train, x_test_pca, y_test):\n",
    "\n",
    "    all_acc_svm = []\n",
    "    all_times_svm = []\n",
    "\n",
    "    for i in range(3):\n",
    "\n",
    "        start_itr = time.time()\n",
    "\n",
    "        print()\n",
    "        print(\"Iteration {}\".format(i+1))\n",
    "        print()\n",
    "\n",
    "        svm_model = SVC(C=0.2, verbose=2, gamma='auto')\n",
    "    #     lsvm_model = LinearSVC(C=c)\n",
    "\n",
    "        print(\"Fitting SVM model\")\n",
    "\n",
    "        svm_model.fit(x_train_pca, y_train)\n",
    "\n",
    "        print(\"SVM model fitted\")\n",
    "    #     lsvm_model.fit(x_train, y_train)\n",
    "\n",
    "    #     print()\n",
    "    #     print(\"Linear SVM ( C = {} )\".format(c))\n",
    "    #     print(\"Training Accuracy : {}%\".format(round((lsvm_model.score(x_train, y_train)) * 100, 2)))\n",
    "    #     print(\"Testing Accuracy : {}%\".format(round((lsvm_model.score(x_test, y_test)) * 100, 2)))\n",
    "\n",
    "        print()\n",
    "        tracc = round((svm_model.score(x_train_pca, y_train)) * 100, 2)\n",
    "        tsacc = round((svm_model.score(x_test_pca, y_test)) * 100, 2)\n",
    "        print(\"Training Accuracy : {}%\".format(tracc))\n",
    "        print(\"Testing Accuracy : {}%\".format(tsacc))\n",
    "\n",
    "        all_acc_svm.append(tsacc)\n",
    "\n",
    "        stop_itr = time.time()\n",
    "        \n",
    "        iter_time = round((stop_itr - start_itr), 3)\n",
    "        all_times_svm.append(iter_time)\n",
    "\n",
    "        print()\n",
    "        print(\"Iteration Time : {}s\".format(iter_time))\n",
    "\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print(\"Average Testing Accuracy (SVM) : {}%\".format(round(np.average(all_acc_svm), 2)))\n",
    "    \n",
    "    return all_acc_svm, all_times_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data.read_data_sets(one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx = dataset.train.data\n",
    "trainy = dataset.train.labels\n",
    "\n",
    "testx = dataset.test.data\n",
    "testy = dataset.test.labels\n",
    "\n",
    "y_train = convert_from_one_hot(trainy)\n",
    "y_test = convert_from_one_hot(testy)\n",
    "\n",
    "y_tr, y_ts = make_labels_for_sparse(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Class Distribution\n",
      "------------------------------\n",
      "Train Labels Distribution\n",
      "{1: 28602, 2: 26628, 3: 29190}\n",
      "\n",
      "Test Labels Distribution\n",
      "{1: 18438, 2: 19740, 3: 19950}\n",
      "==============================\n",
      "\n",
      "\n",
      "==============================\n",
      "Select PCA features (P=180)\n",
      "------------------------------\n",
      "Done\n",
      "==============================\n",
      "\n",
      "\n",
      "==============================\n",
      "Scaling Features using MinMaxScaler\n",
      "------------------------------\n",
      "Done\n",
      "==============================\n",
      "\n",
      "\n",
      "==============================\n",
      "Scaling Features using StdScaler\n",
      "------------------------------\n",
      "Done\n",
      "==============================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\t\tExtreme Learning Machine (ELM) Performance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iteration 1\n",
      "\n",
      "Classification accuracy (L = 1000): 71.73%\n",
      "Time elapsed (Testing): 12.064 sec\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2\n",
      "\n",
      "Classification accuracy (L = 1000): 71.73%\n",
      "Time elapsed (Testing): 12.277 sec\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3\n",
      "\n",
      "Classification accuracy (L = 1000): 71.73%\n",
      "Time elapsed (Testing): 11.777 sec\n",
      "\n",
      "\n",
      "\n",
      "Average Testing Accuracy (ELM) : 71.73%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\t\tNeural Network (NN) Performance\n",
      "--------------------------------------------------------------------------------\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_input (Dense)          (None, 1024)              185344    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           (None, 3)                 3075      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 188,419\n",
      "Trainable params: 188,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Iteration 1\n",
      "\n",
      "Train on 84420 samples, validate on 58128 samples\n",
      "Epoch 1/20\n",
      "84420/84420 [==============================] - 3s 41us/step - loss: 0.4711 - acc: 0.8111 - val_loss: 0.6186 - val_acc: 0.7706\n",
      "Epoch 2/20\n",
      "84420/84420 [==============================] - 3s 35us/step - loss: 0.0872 - acc: 0.9794 - val_loss: 0.7214 - val_acc: 0.7686\n",
      "Epoch 3/20\n",
      "84420/84420 [==============================] - 3s 36us/step - loss: 0.0396 - acc: 0.9940 - val_loss: 0.7898 - val_acc: 0.7749\n",
      "Epoch 4/20\n",
      "84420/84420 [==============================] - 3s 37us/step - loss: 0.0215 - acc: 0.9979 - val_loss: 0.8466 - val_acc: 0.7814\n",
      "Epoch 5/20\n",
      "84420/84420 [==============================] - 3s 34us/step - loss: 0.0134 - acc: 0.9992 - val_loss: 0.8901 - val_acc: 0.7815\n",
      "Epoch 6/20\n",
      "84420/84420 [==============================] - 3s 34us/step - loss: 0.0095 - acc: 0.9994 - val_loss: 0.9524 - val_acc: 0.7815\n",
      "Epoch 7/20\n",
      "84420/84420 [==============================] - 3s 33us/step - loss: 0.0070 - acc: 0.9997 - val_loss: 0.9916 - val_acc: 0.7823\n",
      "Epoch 8/20\n",
      "84420/84420 [==============================] - 3s 37us/step - loss: 0.0053 - acc: 0.9998 - val_loss: 1.0338 - val_acc: 0.7790\n",
      "Epoch 9/20\n",
      "84420/84420 [==============================] - 3s 36us/step - loss: 0.0042 - acc: 0.9999 - val_loss: 1.0660 - val_acc: 0.7813\n",
      "Epoch 10/20\n",
      "84420/84420 [==============================] - 3s 36us/step - loss: 0.0034 - acc: 0.9999 - val_loss: 1.0771 - val_acc: 0.7803\n",
      "Epoch 11/20\n",
      "84420/84420 [==============================] - 3s 36us/step - loss: 0.0028 - acc: 0.9999 - val_loss: 1.1046 - val_acc: 0.7830\n",
      "Epoch 12/20\n",
      "84420/84420 [==============================] - 3s 34us/step - loss: 0.0024 - acc: 0.9999 - val_loss: 1.1312 - val_acc: 0.7795\n",
      "Epoch 13/20\n",
      "84420/84420 [==============================] - 3s 36us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.1499 - val_acc: 0.7802\n",
      "Epoch 14/20\n",
      "84420/84420 [==============================] - 3s 38us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.1798 - val_acc: 0.7790\n",
      "Epoch 15/20\n",
      "84420/84420 [==============================] - 3s 35us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.1959 - val_acc: 0.7805\n",
      "Epoch 16/20\n",
      "84420/84420 [==============================] - 3s 37us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.2306 - val_acc: 0.7786\n",
      "Epoch 17/20\n",
      "84420/84420 [==============================] - 3s 36us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.2312 - val_acc: 0.7797\n",
      "Epoch 18/20\n",
      "84420/84420 [==============================] - 3s 34us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.2474 - val_acc: 0.7804\n",
      "Epoch 19/20\n",
      "84420/84420 [==============================] - 3s 32us/step - loss: 9.3893e-04 - acc: 1.0000 - val_loss: 1.2638 - val_acc: 0.7779\n",
      "Epoch 20/20\n",
      "84420/84420 [==============================] - 3s 35us/step - loss: 8.5776e-04 - acc: 1.0000 - val_loss: 1.2491 - val_acc: 0.7801\n",
      "\n",
      "Testing Accuracy : 77.9%\n",
      "\n",
      "Time elapsed : 60.945s\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2\n",
      "\n",
      "Train on 84420 samples, validate on 58128 samples\n",
      "Epoch 1/20\n",
      "84420/84420 [==============================] - 4s 44us/step - loss: 6.9860e-04 - acc: 1.0000 - val_loss: 1.5343 - val_acc: 0.7755\n",
      "Epoch 2/20\n",
      "84420/84420 [==============================] - 3s 34us/step - loss: 3.4619e-04 - acc: 1.0000 - val_loss: 1.6254 - val_acc: 0.7760\n",
      "Epoch 3/20\n",
      "84420/84420 [==============================] - 3s 35us/step - loss: 1.7391e-04 - acc: 1.0000 - val_loss: 1.7079 - val_acc: 0.7799\n",
      "Epoch 4/20\n",
      "84420/84420 [==============================] - 3s 35us/step - loss: 9.9843e-05 - acc: 1.0000 - val_loss: 1.7831 - val_acc: 0.7789\n",
      "Epoch 5/20\n",
      "84420/84420 [==============================] - 3s 35us/step - loss: 7.7215e-05 - acc: 1.0000 - val_loss: 1.8372 - val_acc: 0.7783\n",
      "Epoch 6/20\n",
      "84420/84420 [==============================] - 3s 34us/step - loss: 5.4820e-05 - acc: 1.0000 - val_loss: 1.9011 - val_acc: 0.7751\n",
      "Epoch 7/20\n",
      "84420/84420 [==============================] - 3s 37us/step - loss: 1.6613e-04 - acc: 1.0000 - val_loss: 2.0637 - val_acc: 0.7714\n",
      "Epoch 8/20\n",
      "84420/84420 [==============================] - 3s 36us/step - loss: 1.5466e-04 - acc: 1.0000 - val_loss: 2.1194 - val_acc: 0.7759\n",
      "Epoch 9/20\n",
      "84420/84420 [==============================] - 3s 33us/step - loss: 1.0315e-04 - acc: 1.0000 - val_loss: 2.1570 - val_acc: 0.7748\n",
      "Epoch 10/20\n",
      "84420/84420 [==============================] - 3s 34us/step - loss: 4.1813e-05 - acc: 1.0000 - val_loss: 2.1501 - val_acc: 0.7766\n",
      "Epoch 11/20\n",
      "84420/84420 [==============================] - 3s 34us/step - loss: 4.2255e-04 - acc: 0.9999 - val_loss: 2.3792 - val_acc: 0.7732\n",
      "Epoch 12/20\n",
      "84420/84420 [==============================] - 3s 34us/step - loss: 3.8629e-04 - acc: 0.9999 - val_loss: 2.2921 - val_acc: 0.7663\n",
      "Epoch 13/20\n",
      "84420/84420 [==============================] - 3s 37us/step - loss: 3.8151e-04 - acc: 0.9999 - val_loss: 2.5398 - val_acc: 0.7675\n",
      "Epoch 14/20\n",
      "84420/84420 [==============================] - 3s 38us/step - loss: 7.2009e-05 - acc: 1.0000 - val_loss: 2.5540 - val_acc: 0.7706\n",
      "Epoch 15/20\n",
      "84420/84420 [==============================] - 3s 37us/step - loss: 4.2709e-05 - acc: 1.0000 - val_loss: 2.5253 - val_acc: 0.7712\n",
      "Epoch 16/20\n",
      "84420/84420 [==============================] - 3s 35us/step - loss: 4.6301e-05 - acc: 1.0000 - val_loss: 2.5775 - val_acc: 0.7690\n",
      "Epoch 17/20\n",
      "84420/84420 [==============================] - 3s 38us/step - loss: 8.9727e-05 - acc: 1.0000 - val_loss: 2.7264 - val_acc: 0.7640\n",
      "Epoch 18/20\n",
      "84420/84420 [==============================] - 3s 37us/step - loss: 2.1883e-04 - acc: 0.9999 - val_loss: 2.7255 - val_acc: 0.7652\n",
      "Epoch 19/20\n",
      "84420/84420 [==============================] - 3s 37us/step - loss: 7.1430e-04 - acc: 0.9998 - val_loss: 2.7344 - val_acc: 0.7727\n",
      "Epoch 20/20\n",
      "84420/84420 [==============================] - 3s 36us/step - loss: 1.0993e-04 - acc: 1.0000 - val_loss: 2.7952 - val_acc: 0.7712\n",
      "\n",
      "Testing Accuracy : 77.27%\n",
      "\n",
      "Time elapsed : 61.562s\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3\n",
      "\n",
      "Train on 84420 samples, validate on 58128 samples\n",
      "Epoch 1/20\n",
      "84420/84420 [==============================] - 4s 45us/step - loss: 5.6205e-05 - acc: 1.0000 - val_loss: 2.8860 - val_acc: 0.7677\n",
      "Epoch 2/20\n",
      "84420/84420 [==============================] - 3s 35us/step - loss: 4.0967e-05 - acc: 1.0000 - val_loss: 2.8725 - val_acc: 0.7744\n",
      "Epoch 3/20\n",
      "84420/84420 [==============================] - 3s 36us/step - loss: 1.6447e-05 - acc: 1.0000 - val_loss: 2.9558 - val_acc: 0.7744\n",
      "Epoch 4/20\n",
      "84420/84420 [==============================] - 3s 37us/step - loss: 8.9801e-05 - acc: 1.0000 - val_loss: 3.0841 - val_acc: 0.7722\n",
      "Epoch 5/20\n",
      "84420/84420 [==============================] - 3s 35us/step - loss: 1.4213e-04 - acc: 1.0000 - val_loss: 3.1215 - val_acc: 0.7692\n",
      "Epoch 6/20\n",
      "84420/84420 [==============================] - 3s 34us/step - loss: 3.7311e-05 - acc: 1.0000 - val_loss: 3.1208 - val_acc: 0.7669\n",
      "Epoch 7/20\n",
      "84420/84420 [==============================] - 3s 36us/step - loss: 2.3998e-05 - acc: 1.0000 - val_loss: 3.1477 - val_acc: 0.7642\n",
      "Epoch 8/20\n",
      "84420/84420 [==============================] - 3s 35us/step - loss: 4.2089e-05 - acc: 1.0000 - val_loss: 3.1696 - val_acc: 0.7649\n",
      "Epoch 9/20\n",
      "84420/84420 [==============================] - 3s 35us/step - loss: 1.1127e-05 - acc: 1.0000 - val_loss: 3.2006 - val_acc: 0.7647\n",
      "Epoch 10/20\n",
      "84420/84420 [==============================] - 3s 32us/step - loss: 1.2300e-04 - acc: 1.0000 - val_loss: 3.1833 - val_acc: 0.7722\n",
      "Epoch 11/20\n",
      "84420/84420 [==============================] - 3s 34us/step - loss: 1.2643e-05 - acc: 1.0000 - val_loss: 3.2166 - val_acc: 0.7709\n",
      "Epoch 12/20\n",
      "84420/84420 [==============================] - 3s 35us/step - loss: 9.5612e-05 - acc: 1.0000 - val_loss: 3.3837 - val_acc: 0.7660\n",
      "Epoch 13/20\n",
      "84420/84420 [==============================] - 3s 36us/step - loss: 8.1399e-05 - acc: 1.0000 - val_loss: 3.3469 - val_acc: 0.7715\n",
      "Epoch 14/20\n",
      "84420/84420 [==============================] - 3s 34us/step - loss: 2.5008e-05 - acc: 1.0000 - val_loss: 3.3051 - val_acc: 0.7720\n",
      "Epoch 15/20\n",
      "84420/84420 [==============================] - 3s 33us/step - loss: 5.4336e-05 - acc: 1.0000 - val_loss: 3.5286 - val_acc: 0.7659\n",
      "Epoch 16/20\n",
      "84420/84420 [==============================] - 3s 33us/step - loss: 5.6987e-05 - acc: 1.0000 - val_loss: 3.6382 - val_acc: 0.7638\n",
      "Epoch 17/20\n",
      "84420/84420 [==============================] - 3s 33us/step - loss: 4.2661e-04 - acc: 0.9999 - val_loss: 3.5165 - val_acc: 0.7611\n",
      "Epoch 18/20\n",
      "84420/84420 [==============================] - 3s 34us/step - loss: 2.1248e-04 - acc: 0.9999 - val_loss: 3.4666 - val_acc: 0.7674\n",
      "Epoch 19/20\n",
      "84420/84420 [==============================] - 3s 35us/step - loss: 2.1409e-04 - acc: 0.9999 - val_loss: 3.5845 - val_acc: 0.7730\n",
      "Epoch 20/20\n",
      "84420/84420 [==============================] - 3s 32us/step - loss: 1.6370e-04 - acc: 1.0000 - val_loss: 3.6527 - val_acc: 0.7643\n",
      "\n",
      "Testing Accuracy : 76.83%\n",
      "\n",
      "Time elapsed : 60.05s\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Testing Accuracy (NN) : 77.33333333333333%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\t\tSupport Vector Machine (SVM) Performance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 1\n",
      "\n",
      "Fitting SVM model\n",
      "[LibSVM]SVM model fitted\n",
      "\n",
      "Training Accuracy : 100.0%\n",
      "Testing Accuracy : 81.08%\n",
      "\n",
      "Iteration Time : 704.127s\n",
      "\n",
      "Iteration 2\n",
      "\n",
      "Fitting SVM model\n",
      "[LibSVM]SVM model fitted\n",
      "\n",
      "Training Accuracy : 100.0%\n",
      "Testing Accuracy : 81.08%\n",
      "\n",
      "Iteration Time : 702.285s\n",
      "\n",
      "Iteration 3\n",
      "\n",
      "Fitting SVM model\n",
      "[LibSVM]SVM model fitted\n",
      "\n",
      "Training Accuracy : 100.0%\n",
      "Testing Accuracy : 81.08%\n",
      "\n",
      "Iteration Time : 703.063s\n",
      "\n",
      "\n",
      "Average Testing Accuracy (SVM) : 81.08%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\t\tRandom Forest (RF) Performance\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 1\n",
      "Testing Accuracy : %\n",
      "Iteration 2\n",
      "Testing Accuracy : %\n",
      "Iteration 3\n",
      "Testing Accuracy : %\n",
      "\n",
      "Average Testing Accuracy (RF) : 77.75828057619965%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "All Evaluations Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*30)\n",
    "print(\"Class Distribution\")\n",
    "print(\"-\"*30)\n",
    "check_class_imbalance(y_train, y_test)\n",
    "print(\"=\"*30)\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"=\"*30)\n",
    "print(\"Select PCA features (P=180)\")\n",
    "print(\"-\"*30)\n",
    "x_train_pca, x_test_pca = make_pca_features(trainx, testx)\n",
    "print(\"Done\")\n",
    "print(\"=\"*30)\n",
    "print()\n",
    "print()\n",
    "print(\"=\"*30)\n",
    "print(\"Scaling Features using MinMaxScaler\")\n",
    "print(\"-\"*30)\n",
    "xtr_scaled_mms, xts_scaled_mms, xtr_scaled_mms_pca, xts_scaled_mms_pca = make_mms_scaled_features(trainx, testx, x_train_pca, x_test_pca)\n",
    "print(\"Done\")\n",
    "print(\"=\"*30)\n",
    "print()\n",
    "print()\n",
    "print(\"=\"*30)\n",
    "print(\"Scaling Features using StdScaler\")\n",
    "print(\"-\"*30)\n",
    "xtr_scaled_std, xts_scaled_std, xtr_scaled_std_pca, xts_scaled_std_pca = make_std_scaled_features(trainx, testx, x_train_pca, x_test_pca)\n",
    "print(\"Done\")\n",
    "print(\"=\"*30)\n",
    "print()\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"\\t\\tExtreme Learning Machine (ELM) Performance\")\n",
    "print(\"-\"*80)\n",
    "all_acc_elm, all_times_elm = calculate_elm_performance(xtr_scaled_std_pca, trainy, xts_scaled_std_pca, testy)\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"\\t\\tNeural Network (NN) Performance\")\n",
    "print(\"-\"*80)\n",
    "all_acc_nn, all_times_nn = calculate_nn_performance(x_train_pca, y_tr, x_test_pca, y_ts)\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"\\t\\tSupport Vector Machine (SVM) Performance\")\n",
    "print(\"-\"*80)\n",
    "all_acc_svm, all_times_svm = calculate_svm_performance(x_train_pca, y_train, x_test_pca, y_test)\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"\\t\\tRandom Forest (RF) Performance\")\n",
    "print(\"-\"*80)\n",
    "all_acc_rf, all_times_rf = calculate_rf_performance(xtr_scaled_std_pca, y_train, xts_scaled_std_pca, y_test)\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"All Evaluations Done!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "\tELM Performance\n",
      "----------------------------------------\n",
      "Iteration 1\n",
      "\tAverage Accuracy : 71.73%\n",
      "\tAverage Time : 12.064 secs\n",
      "\n",
      "\n",
      "Iteration 2\n",
      "\tAverage Accuracy : 71.73%\n",
      "\tAverage Time : 12.277 secs\n",
      "\n",
      "\n",
      "Iteration 3\n",
      "\tAverage Accuracy : 71.73%\n",
      "\tAverage Time : 11.777 secs\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "\n",
      "========================================\n",
      "\tNeural Network Performance\n",
      "----------------------------------------\n",
      "Iteration 1\n",
      "\tAverage Accuracy : 77.9%\n",
      "\tAverage Time : 60.945 secs\n",
      "\n",
      "\n",
      "Iteration 2\n",
      "\tAverage Accuracy : 77.27%\n",
      "\tAverage Time : 61.562 secs\n",
      "\n",
      "\n",
      "Iteration 3\n",
      "\tAverage Accuracy : 76.83%\n",
      "\tAverage Time : 60.05 secs\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "\n",
      "========================================\n",
      "\tSVM Performance\n",
      "----------------------------------------\n",
      "Iteration 1\n",
      "\tAverage Accuracy : 81.08%\n",
      "\tAverage Time : 704.127 secs\n",
      "\n",
      "\n",
      "Iteration 2\n",
      "\tAverage Accuracy : 81.08%\n",
      "\tAverage Time : 702.285 secs\n",
      "\n",
      "\n",
      "Iteration 3\n",
      "\tAverage Accuracy : 81.08%\n",
      "\tAverage Time : 703.063 secs\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "\n",
      "========================================\n",
      "\tRF Performance\n",
      "----------------------------------------\n",
      "Iteration 1\n",
      "\tAverage Accuracy : 77.79%\n",
      "\tAverage Time : 22.563 secs\n",
      "\n",
      "\n",
      "Iteration 2\n",
      "\tAverage Accuracy : 77.8%\n",
      "\tAverage Time : 22.254 secs\n",
      "\n",
      "\n",
      "Iteration 3\n",
      "\tAverage Accuracy : 77.68%\n",
      "\tAverage Time : 22.349 secs\n",
      "\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*40)\n",
    "print(\"\\tELM Performance\")\n",
    "print(\"-\"*40)\n",
    "for i in range(3):\n",
    "    print('Iteration {}'.format(i+1))\n",
    "    print(\"\\tAverage Accuracy : {}%\".format(all_acc_elm[i]))\n",
    "    print(\"\\tAverage Time : {} secs\".format(all_times_elm[i]))\n",
    "    print()\n",
    "    print()\n",
    "print(\"=\"*40)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"\\tNeural Network Performance\")\n",
    "print(\"-\"*40)\n",
    "for i in range(3):\n",
    "    print('Iteration {}'.format(i+1))\n",
    "    print(\"\\tAverage Accuracy : {}%\".format(all_acc_nn[i]))\n",
    "    print(\"\\tAverage Time : {} secs\".format(all_times_nn[i]))\n",
    "    print()\n",
    "    print()\n",
    "print(\"=\"*40)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"\\tSVM Performance\")\n",
    "print(\"-\"*40)\n",
    "for i in range(3):\n",
    "    print('Iteration {}'.format(i+1))\n",
    "    print(\"\\tAverage Accuracy : {}%\".format(all_acc_svm[i]))\n",
    "    print(\"\\tAverage Time : {} secs\".format(all_times_svm[i]))\n",
    "    print()\n",
    "    print()\n",
    "print(\"=\"*40)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"\\tRF Performance\")\n",
    "print(\"-\"*40)\n",
    "for i in range(3):\n",
    "    all_acc_rf[i] = round(all_acc_rf[i], 2)\n",
    "    print('Iteration {}'.format(i+1))\n",
    "    print(\"\\tAverage Accuracy : {}%\".format(all_acc_rf[i]))\n",
    "    print(\"\\tAverage Time : {} secs\".format(all_times_rf[i]))\n",
    "    print()\n",
    "    print()\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = np.arange(3, step=1) + 1\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "ax.bar(iterations-0.3, all_acc_elm, width=0.2, label='ELM')\n",
    "ax.bar(iterations-0.1, all_acc_nn, width=0.2, label='NN')\n",
    "ax.bar(iterations+0.1, all_acc_svm, width=0.2, label='SVM')\n",
    "ax.bar(iterations+0.3, all_acc_rf, width=0.2, label='RF')\n",
    "\n",
    "plt.ylim(50, 100)\n",
    "plt.xticks(np.arange(3) + 1, )\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Average Testing Accuracy (%)')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = np.arange(3, step=1) + 1\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "ax.bar(iterations-0.3, all_times_elm, width=0.2, label='ELM')\n",
    "ax.bar(iterations-0.1, all_times_nn, width=0.2, label='NN')\n",
    "ax.bar(iterations+0.1, all_times_svm, width=0.2, label='SVM')\n",
    "ax.bar(iterations+0.3, all_times_rf, width=0.2, label='RF')\n",
    "\n",
    "# plt.plot(iterations, all_acc_elm, 'or-', label='ELM')\n",
    "# plt.plot(iterations, all_acc_nn, 'og-', label='NN')\n",
    "# plt.plot(iterations, all_acc_svm, 'ob-', label='SVM')\n",
    "plt.ylim(0, 900)\n",
    "plt.xticks(np.arange(3) + 1,)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Testing Time (seconds)')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\t\tBest Results\n",
      "--------------------------------------------------\n",
      "Average Testing Accuracy : 81.08% (SVM)\n",
      "--------------------------------------------------\n",
      "Average Testing Time (for SVM) : 703.158 secs\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"\\t\\tBest Results\")\n",
    "print(\"-\"*50)\n",
    "print(\"Average Testing Accuracy : {}% (SVM)\".format(max(all_acc_svm)))\n",
    "print(\"-\"*50)\n",
    "print(\"Average Testing Time (for SVM) : {} secs\".format(round(np.average(all_times_svm), 3)))\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\t\tAll Average Results\n",
      "--------------------------------------------------\n",
      "Testing Accuracy (ELM) : 71.73%\n",
      "\n",
      "Testing Time (ELM) : 12.039 secs\n",
      "--------------------------------------------------\n",
      "Testing Accuracy (NN) : 77.33%\n",
      "\n",
      "Testing Time (NN) : 60.852 secs\n",
      "--------------------------------------------------\n",
      "Testing Accuracy (SVM) : 81.08%\n",
      "\n",
      "Testing Time (SVM) : 703.158 secs\n",
      "--------------------------------------------------\n",
      "Testing Accuracy (RF) : 77.76%\n",
      "\n",
      "Testing Time (RF) : 22.389 secs\n",
      "--------------------------------------------------\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"\\t\\tAll Average Results\")\n",
    "print(\"-\"*50)\n",
    "print(\"Testing Accuracy (ELM) : {}%\".format(round(np.average(all_acc_elm), 2)))\n",
    "print()\n",
    "print(\"Testing Time (ELM) : {} secs\".format(round(np.average(all_times_elm), 3)))\n",
    "print(\"-\"*50)\n",
    "print(\"Testing Accuracy (NN) : {}%\".format(round(np.average(all_acc_nn), 2)))\n",
    "print()\n",
    "print(\"Testing Time (NN) : {} secs\".format(round(np.average(all_times_nn), 3)))\n",
    "print(\"-\"*50)\n",
    "print(\"Testing Accuracy (SVM) : {}%\".format(round(np.average(all_acc_svm), 2)))\n",
    "print()\n",
    "print(\"Testing Time (SVM) : {} secs\".format(round(np.average(all_times_svm), 3)))\n",
    "print(\"-\"*50)\n",
    "print(\"Testing Accuracy (RF) : {}%\".format(round(np.average(all_acc_rf), 2)))\n",
    "print()\n",
    "print(\"Testing Time (RF) : {} secs\".format(round(np.average(all_times_rf), 3)))\n",
    "print(\"-\"*50)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
